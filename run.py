import asyncio
import time
import json
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig
from crawl4ai.extraction_strategy import JsonCssExtractionStrategy

from notify import send_wechat

# é…ç½®å‚æ•°
TARGET_URL = "https://www.ur-net.go.jp/chintai/kanto/kanagawa/40_1750.html"
LOG_FILE = "ur_stock.log"

async def monitor_ur():
    # 1. æ›´æ–° Schema é…ç½®
    schema = {
        "name": "UR Room Detailed List",
        "baseSelector": "tr.js-log-item", 
        "fields": [
            {"name": "room_id", "selector": "td.rep_room-name", "type": "text"},    # æˆ¿å·
            {"name": "type", "selector": "td.rep_room-type", "type": "text"},       # æˆ·å‹
            {"name": "area", "selector": "td.rep_room-floor", "type": "text"},      # é¢ç§¯
            {"name": "floor_info", "selector": "td.rep_room-kai", "type": "text"},  # æ¥¼å±‚
            # æ ¹æ®å›¾ç‰‡ï¼Œç§Ÿé‡‘åœ¨ span class="item_price rep_room-price" ä¸­
            {"name": "rent", "selector": "span.rep_room-price", "type": "text"},
            # (å¯é€‰) å¦‚æœä½ è¿˜éœ€è¦å…±ç›Šè´¹ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Š
            # {"name": "fee", "selector": "span.rep_room-commonfee", "type": "text"} 
        ],
    }
    
    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=False)

    browser_cfg = BrowserConfig(
        headless=True, 
        enable_stealth=True,
        browser_type="chromium"
    )

    run_cfg = CrawlerRunConfig(
        # 1. ã€ä¿®æ”¹ç‚¹ã€‘ä¸è¦ç­‰å…·ä½“çš„æˆ¿æºè¡Œï¼Œæ”¹ä¸ºç­‰é¡µé¢æ ‡é¢˜æˆ– body
        # è¿™æ ·æ— è®ºæœ‰æˆ¿æ²¡æˆ¿ï¼Œåªè¦é¡µé¢æ‰“å¼€äº†å°±ä¼šç»§ç»­
        wait_for="css:body", 
        
        # 2. ã€æ–°å¢ç‚¹ã€‘ç»™ JS ä¸€ç‚¹æ—¶é—´åŠ è½½æ•°æ®
        # å³ä½¿æ²¡æˆ¿ï¼Œç­‰2-3ç§’ä¹Ÿèƒ½ç¡®ä¿ä¸æ˜¯å› ä¸ºç½‘é€Ÿæ…¢å¯¼è‡´çš„è¯¯åˆ¤
        delay_before_return_html=3.0,

        extraction_strategy=extraction_strategy,
        cache_mode="bypass"
    )

    async with AsyncWebCrawler(config=browser_cfg) as crawler:
        result = await crawler.arun(url=TARGET_URL, config=run_cfg)
        
        if result.success and result.extracted_content:
            rooms = json.loads(result.extracted_content)
            
            # è¿‡æ»¤æ‰ç©ºè¡Œ
            valid_rooms = [r for r in rooms if r.get("room_id")]
            
            if valid_rooms:
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
                print(f"\n[{timestamp}] ğŸ“¢ å‘ç° {len(valid_rooms)} ä¸ªå¯ç”¨æˆ¿æºï¼š")
                print("=" * 80) #ç¨å¾®æ‹‰é•¿åˆ†å‰²çº¿
                
                result_entry = f"[{timestamp}] æ£€æµ‹åˆ°æˆ¿æº: \n------\n"
                for room in valid_rooms:
                    # â–¼â–¼â–¼ åœ¨è¾“å‡ºä¸­åŠ å…¥ç§Ÿé‡‘ â–¼â–¼â–¼
                    rent_price = room.get('rent', 'æœªçŸ¥').strip()
                    
                    output = (f"æˆ¿å·: {room['room_id'].strip()} | "
                              f"ç§Ÿé‡‘: {rent_price} | "  # æ–°å¢æ˜¾ç¤º
                              f"æˆ·å‹: {room['type'].strip()} | "
                              f"é¢ç§¯: {room['area'].strip()} | "
                              f"æ¥¼å±‚: {room['floor_info'].strip()}")
                    print(output)
                    
                    # è®°å½•æ—¥å¿—ä¹ŸåŠ ä¸Šä»·æ ¼
                    result_entry += f" {output}\n------\n"
                
                # å†™å…¥æ—¥å¿—
                # with open(LOG_FILE, "a", encoding="utf-8") as f:
                #     f.write(result_entry + "\n")
                # print("=" * 80)
                
                # â–¼â–¼â–¼ 4. å‘é€å¾®ä¿¡æ¨é€ â–¼â–¼â–¼
                print("æ­£åœ¨æ¨é€å¾®ä¿¡é€šçŸ¥...")
                send_wechat(result_entry)
                
            else:
                print(f"[{time.strftime('%H:%M:%S')}] é¡µé¢å·²åŠ è½½ï¼Œä½†æœªå‘ç°å…·ä½“æˆ¿æºè¡Œã€‚")
        else:
            print(f"[{time.strftime('%H:%M:%S')}] ç›®å‰æ— æˆ¿ï¼ˆæœªæ‰¾åˆ° tr.js-log-itemï¼‰ã€‚")

if __name__ == "__main__":
    asyncio.run(monitor_ur())
